# Cognition 002：对话总结——开源与传播策略（脱敏示例）

## 背景

我在考虑把一个“私有个人仓库”（个人记忆/经验系统）抽象出一个 **可分享/可开源的 MEMO 模板仓库**，用于传播与引导更多人采用。

这个认知笔记的目的不是写 marketing 文案，而是把讨论沉淀成**可复用的定位、边界、MVP 与传播策略**。

## 核心定位（要交付什么）

我们交付的不是“自动化产品”，而是一套 **protocol + reference workflow**：

- **稳定 outputs**：Objects + fields + conventions（例如 People cards / Projects / Decisions / Signals）
- **开放 inputs**：聊天、截图、链接、命令输出、长文等都可以作为输入
- **AI/Agent 是可插拔编译器**：把碎片“编译”为协议化输出；仓库（Git/Markdown）是长期真源

## 受众（谁会用）

优先面向能用 Code Agent（Codex / Cursor / Claude Code 等）的高技能用户（power users）：

- 工程师、研究生、创业者、AI 重度用户
- 希望“低摩擦输入 → 批处理结构化 → 可追溯落盘 → 可组合（composable）”的用户

## MVP 范围（最小可跑通闭环）

**Template Repo + 可复制的 prompts/skills + 1–2 条可跑通的示例**。

建议把关键原则写死：

- 输出永远写回 Markdown 文件（可 `git diff` / 可回滚）
- prompts/skills 版本化（把约束写进协议与技能，而不是靠口头约定）
- search-first（`rg`）为默认路径；脚本只做加速，不做绑定

## 传播策略：Demo ≠ Product

如果要做网页，定位为 **无状态 Playground/Demo**：

- No DB / No Auth / No storage（不保存用户输入）
- 默认 BYOK（用户自带 key），确保成本可控
- 目标是 30 秒看见价值：输入碎片 → 输出结构化 Markdown → 可复制写回

## 新洞见：Agent 工作流也是一种 Benchmark

- 静态 benchmark 容易过拟合；“真实工作流（读写文件、Git、长期约束）”更接近真实能力评测。
- 在“写回 Markdown 文件并产生 git diff”的闭环里，用户的接受/修改/回滚天然提供弱监督信号（什么输出是可用的）。
- 因此，这套 MEMO 模板除了是生产力框架，也可以被视为一种 **Living Benchmark / Eval Harness for Human-Agent Collaboration**。

## 未解问题（后续要验证）

- Signals 是否需要单独一级对象，还是先作为一种 tags/notes 形态存在？
- 公开版需要到什么程度的“参考实现”（CLI/校验/示例 walkthrough）才能让新人真正上手？
- Web Demo 的边界如何写清楚，避免被误解为 SaaS（尤其是隐私与成本）？
